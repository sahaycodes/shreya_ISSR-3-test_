{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç **Top 5 Locations with Highest Crisis Discussions:**\n",
      "1. canada: 44 mentions\n",
      "2. california: 40 mentions\n",
      "3. europe: 34 mentions\n",
      "4. uk: 32 mentions\n",
      "5. florida: 28 mentions\n",
      "\n",
      "üåç **Heatmap saved as:** crisis_heatmap.html\n",
      "üìä **Top crisis locations plot saved as:** top_crisis_locations.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1262/2331879298.py:145: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[loc[0] for loc in top_locations], y=[loc[1] for loc in top_locations], palette=\"Reds\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from folium.plugins import HeatMap\n",
    "from collections import Counter\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import spacy\n",
    "from geotext import GeoText\n",
    "\n",
    "# Load SpaCy NLP Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize OpenStreetMap Geocoder\n",
    "geolocator = Nominatim(user_agent=\"geo_locator\", timeout=10)\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"reddit_data_location.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: 'reddit_data_location.csv' not found!\")\n",
    "    exit()\n",
    "\n",
    "# Ensure required columns exist\n",
    "if \"content\" not in df.columns:\n",
    "    print(\"‚ùå Error: Missing 'content' column!\")\n",
    "    exit()\n",
    "\n",
    "# List of invalid words that are NOT real locations\n",
    "INVALID_LOCATIONS = {\n",
    "    \"n't\", \"ER\", \"it\", \"he\", \"she\", \"they\", \"us\", \"me\", \"here\", \"there\",\n",
    "    \"somewhere\", \"anywhere\", \"everywhere\", \"world\", \"earth\", \"planet\", \"universe\",\n",
    "    \"USA\", \"UK\", \"US\", \"India\", \"Canada\", \"Europe\", \"Asia\", \"phobia\", \"kinda\",\n",
    "    \"lot\", \"many\", \"some\", \"all\", \"whole\", \"most\", \"person\", \"people\", \"someone\", \"everyone\"\n",
    "}\n",
    "\n",
    "# Function to validate location using OpenStreetMap\n",
    "def validate_location_with_osm(location):\n",
    "    \"\"\"Checks if the location is real by querying OpenStreetMap (OSM).\"\"\"\n",
    "    if pd.isna(location) or not isinstance(location, str):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        geo = geolocator.geocode(location, timeout=10)\n",
    "        return geo is not None  # Return True if OSM can find the location\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Function to extract location from text using multiple methods\n",
    "def extract_location(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return None  \n",
    "\n",
    "    # 1Ô∏è‚É£ Named Entity Recognition (NER) using SpaCy\n",
    "    doc = nlp(text)\n",
    "    ner_locations = [ent.text for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]]\n",
    "    ner_locations = [loc for loc in ner_locations if loc.lower() not in INVALID_LOCATIONS]\n",
    "\n",
    "    # Validate extracted locations with OpenStreetMap\n",
    "    ner_locations = [loc for loc in ner_locations if validate_location_with_osm(loc)]\n",
    "\n",
    "    if ner_locations:\n",
    "        return ner_locations[0]  # Return the first valid location\n",
    "\n",
    "    # 2Ô∏è‚É£ Regex-based location extraction\n",
    "    location_match = re.search(r\"(live in|from|located in|born in) ([A-Za-z\\s]+)\", text, re.IGNORECASE)\n",
    "    if location_match:\n",
    "        location = location_match.group(2).strip()\n",
    "        if location.lower() not in INVALID_LOCATIONS and validate_location_with_osm(location):\n",
    "            return location\n",
    "\n",
    "    # 3Ô∏è‚É£ GeoText City Name Recognition\n",
    "    places = GeoText(text).cities\n",
    "    valid_places = [place for place in places if validate_location_with_osm(place)]\n",
    "    \n",
    "    if valid_places:\n",
    "        return valid_places[0]  \n",
    "\n",
    "    return None  \n",
    "\n",
    "# Function to get latitude & longitude using OpenStreetMap\n",
    "def get_lat_lon(location):\n",
    "    \"\"\"Returns latitude & longitude of a location using OpenStreetMap (Nominatim).\"\"\"\n",
    "    if pd.isna(location) or not isinstance(location, str):\n",
    "        return None, None  # Ensure valid input\n",
    "    \n",
    "    try:\n",
    "        geo = geolocator.geocode(location, timeout=10)\n",
    "        if geo:\n",
    "            return geo.latitude, geo.longitude\n",
    "    except GeocoderTimedOut:\n",
    "        print(f\"‚ö† Geocoding timed out for '{location}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Geocoding failed for '{location}': {e}\")\n",
    "    \n",
    "    return None, None  # Return None if lookup fails\n",
    "\n",
    "# Extract locations for each post\n",
    "df[\"location\"] = df[\"content\"].apply(extract_location)\n",
    "\n",
    "# Remove rows without valid locations\n",
    "df = df.dropna(subset=[\"location\"])\n",
    "\n",
    "# Get latitude and longitude for each unique location\n",
    "unique_locations = df[\"location\"].unique()\n",
    "location_dict = {}\n",
    "\n",
    "for loc in unique_locations:\n",
    "    lat, lon = get_lat_lon(loc)\n",
    "    if lat and lon:\n",
    "        location_dict[loc] = (lat, lon)\n",
    "\n",
    "# Assign latitude & longitude to the dataframe\n",
    "df[\"latitude\"] = df[\"location\"].map(lambda x: location_dict.get(x, (None, None))[0])\n",
    "df[\"longitude\"] = df[\"location\"].map(lambda x: location_dict.get(x, (None, None))[1])\n",
    "\n",
    "# Remove rows where geolocation lookup failed\n",
    "df = df.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Count top locations\n",
    "top_locations = Counter(df[\"location\"]).most_common(5)\n",
    "\n",
    "# Display top 5 crisis locations\n",
    "print(\"\\nüìç **Top 5 Locations with Highest Crisis Discussions:**\")\n",
    "for i, (location, count) in enumerate(top_locations, 1):\n",
    "    print(f\"{i}. {location}: {count} mentions\")\n",
    "\n",
    "# Create a heatmap of crisis locations\n",
    "map_center = [df[\"latitude\"].mean(), df[\"longitude\"].mean()]  # Center map around data\n",
    "m = folium.Map(location=map_center, zoom_start=4)\n",
    "\n",
    "# Add heatmap layer\n",
    "heat_data = list(zip(df[\"latitude\"], df[\"longitude\"]))\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "# Save the heatmap\n",
    "heatmap_file = \"crisis_heatmap.html\"\n",
    "m.save(heatmap_file)\n",
    "\n",
    "# Visualization: Top 5 Locations with Highest Crisis Discussions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=[loc[0] for loc in top_locations], y=[loc[1] for loc in top_locations], palette=\"Reds\")\n",
    "plt.title(\"Top 5 Locations with Highest Crisis Discussions\")\n",
    "plt.xlabel(\"Location\")\n",
    "plt.ylabel(\"Number of Mentions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\"top_crisis_locations.png\")  # Save plot instead of displaying\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nüåç **Heatmap saved as:** {heatmap_file}\")\n",
    "print(f\"üìä **Top crisis locations plot saved as:** top_crisis_locations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç **Top 5 Locations with Highest Crisis Discussions:**\n",
      "1. kinda: 91 mentions\n",
      "2. canada: 44 mentions\n",
      "3. california: 38 mentions\n",
      "4. europe: 34 mentions\n",
      "5. phobia: 32 mentions\n",
      "\n",
      "üåç **Heatmap saved as:** crisis_heatmap.html\n",
      "üìä **Top crisis locations plot saved as:** top_crisis_locations.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9714/3030613202.py:128: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=[loc[0] for loc in top_locations], y=[loc[1] for loc in top_locations], palette=\"Reds\")\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
